<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Randal S. Olson and Ryan J. Urbanowicz">
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Using skrebate - scikit-rebate</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Using skrebate";
    var mkdocs_page_input_path = "using.md";
    var mkdocs_page_url = "/using/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> scikit-rebate</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../installing/">Installation</a>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">Using skrebate</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#relieff">ReliefF</a></li>
    

    <li class="toctree-l2"><a href="#surf">SURF</a></li>
    

    <li class="toctree-l2"><a href="#surf_1">SURF*</a></li>
    

    <li class="toctree-l2"><a href="#multisurf">MultiSURF</a></li>
    

    <li class="toctree-l2"><a href="#multisurf_1">MultiSURF*</a></li>
    

    <li class="toctree-l2"><a href="#turf">TURF</a></li>
    

    <li class="toctree-l2"><a href="#acquiring-feature-importance-scores">Acquiring feature importance scores</a></li>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Examples</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../examples/GAMETES_Example/">GAMETES Example</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../contributing/">Contributing</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../releases/">Release Notes</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../citing/">Citing</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../support/">Support</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">scikit-rebate</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Using skrebate</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/EpistasisLab/scikit-rebate/edit/master/docs_sources/using.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <p>We have designed the Relief algorithms to be integrated directly into scikit-learn machine learning workflows. Below, we provide code samples showing how the various Relief algorithms can be used as feature selection methods in scikit-learn pipelines.</p>
<p>For details on the algorithmic differences between the various Relief algorithms, please refer to <a href="https://biodatamining.biomedcentral.com/articles/10.1186/1756-0381-2-5">this research paper</a>.</p>
<h2 id="relieff">ReliefF</h2>
<p>ReliefF is the most basic of the Relief-based feature selection algorithms, and it requires you to specify the number of nearest neighbors to consider in the scoring algorithm. The parameters for the ReliefF algorithm are as follows:</p>
<table>
<tr>
<th>Parameter</th>
<th width="15%">Valid values</th>
<th>Effect</th>
</tr>
<tr>
<td>n_features_to_select</td>
<td>Any positive integer</td>
<td>The number of best features to retain after the feature selection process. The "best" features are the highest-scored features according to the ReliefF scoring process.</td>
</tr>
<tr>
<td>n_neighbors</td>
<td>Any positive integer</td>
<td>The number of nearest neighbors to consider in the ReliefF feature scoring process. Generally the more neighbors the algorithm considers, the better the scores are. However, considering more neighbors makes the algorithm run slower.</td>
</tr>
<tr>
<td>discrete_limit</td>
<td>Any positive integer</td>
<td>Value used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.</td>
</tr>
<tr>
<td>n_jobs</td>
<td>Any positive integer or -1</td>
<td>The number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.</td>
</tr>
</table>

<pre><code class="python">import pandas as pd
import numpy as np
from sklearn.pipeline import make_pipeline
from skrebate import ReliefF
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

genetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'
                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.csv.gz',
                           sep='\t', compression='gzip')

features, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values

clf = make_pipeline(ReliefF(n_features_to_select=2, n_neighbors=100),
                    RandomForestClassifier(n_estimators=100))

print(np.mean(cross_val_score(clf, features, labels)))
&gt;&gt;&gt; 0.795
</code></pre>

<h2 id="surf">SURF</h2>
<p>SURF, SURF*, and MultiSURF are all extensions to the ReliefF algorithm that automatically determine the ideal number of neighbors to consider when scoring the features.</p>
<table>
<tr>
<th>Parameter</th>
<th width="15%">Valid values</th>
<th>Effect</th>
</tr>
<tr>
<td>n_features_to_select</td>
<td>Any positive integer</td>
<td>The number of best features to retain after the feature selection process. The "best" features are the highest-scored features according to the SURF scoring process.</td>
</tr>
<tr>
<td>discrete_limit</td>
<td>Any positive integer</td>
<td>Value used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.</td>
</tr>
<tr>
<td>n_jobs</td>
<td>Any positive integer or -1</td>
<td>The number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.</td>
</tr>
</table>

<pre><code class="python">import pandas as pd
import numpy as np
from sklearn.pipeline import make_pipeline
from skrebate import SURF
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

genetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'
                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.csv.gz',
                           sep='\t', compression='gzip')

features, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values

clf = make_pipeline(SURF(n_features_to_select=2),
                    RandomForestClassifier(n_estimators=100))

print(np.mean(cross_val_score(clf, features, labels)))
&gt;&gt;&gt; 0.795
</code></pre>

<h2 id="surf_1">SURF*</h2>
<table>
<tr>
<th>Parameter</th>
<th width="15%">Valid values</th>
<th>Effect</th>
</tr>
<tr>
<td>n_features_to_select</td>
<td>Any positive integer</td>
<td>The number of best features to retain after the feature selection process. The "best" features are the highest-scored features according to the SURF* scoring process.</td>
</tr>
<tr>
<td>discrete_limit</td>
<td>Any positive integer</td>
<td>Value used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.</td>
</tr>
<tr>
<td>n_jobs</td>
<td>Any positive integer or -1</td>
<td>The number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.</td>
</tr>
</table>

<pre><code class="python">import pandas as pd
import numpy as np
from sklearn.pipeline import make_pipeline
from skrebate import SURFstar
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

genetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'
                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.csv.gz',
                           sep='\t', compression='gzip')

features, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values

clf = make_pipeline(SURFstar(n_features_to_select=2),
                    RandomForestClassifier(n_estimators=100))

print(np.mean(cross_val_score(clf, features, labels)))
&gt;&gt;&gt; 0.795
</code></pre>

<h2 id="multisurf">MultiSURF</h2>
<table>
<tr>
<th>Parameter</th>
<th width="15%">Valid values</th>
<th>Effect</th>
</tr>
<tr>
<td>n_features_to_select</td>
<td>Any positive integer</td>
<td>The number of best features to retain after the feature selection process. The "best" features are the highest-scored features according to the MultiSURF scoring process.</td>
</tr>
<tr>
<td>discrete_limit</td>
<td>Any positive integer</td>
<td>Value used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.</td>
</tr>
<tr>
<td>n_jobs</td>
<td>Any positive integer or -1</td>
<td>The number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.</td>
</tr>
</table>

<pre><code class="python">import pandas as pd
import numpy as np
from sklearn.pipeline import make_pipeline
from skrebate import MultiSURF
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

genetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'
                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.csv.gz',
                           sep='\t', compression='gzip')

features, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values

clf = make_pipeline(MultiSURF(n_features_to_select=2),
                    RandomForestClassifier(n_estimators=100))

print(np.mean(cross_val_score(clf, features, labels)))
&gt;&gt;&gt; 0.795
</code></pre>

<h2 id="multisurf_1">MultiSURF*</h2>
<table>
<tr>
<th>Parameter</th>
<th width="15%">Valid values</th>
<th>Effect</th>
</tr>
<tr>
<td>n_features_to_select</td>
<td>Any positive integer</td>
<td>The number of best features to retain after the feature selection process. The "best" features are the highest-scored features according to the MultiSURF* scoring process.</td>
</tr>
<tr>
<td>discrete_limit</td>
<td>Any positive integer</td>
<td>Value used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.</td>
</tr>
<tr>
<td>n_jobs</td>
<td>Any positive integer or -1</td>
<td>The number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.</td>
</tr>
</table>

<pre><code class="python">import pandas as pd
import numpy as np
from sklearn.pipeline import make_pipeline
from skrebate import MultiSURFstar
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

genetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'
                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.csv.gz',
                           sep='\t', compression='gzip')

features, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values

clf = make_pipeline(MultiSURFstar(n_features_to_select=2),
                    RandomForestClassifier(n_estimators=100))

print(np.mean(cross_val_score(clf, features, labels)))
&gt;&gt;&gt; 0.795
</code></pre>

<h2 id="turf">TURF</h2>
<p>TURF advances the feature selection process from a single round to a multi-round process, and can be used in conjunction with any of the Relief-based algorithms. TURF begins with all of the features in the first round, scores them using one of the Relief-based algorithms, then eliminates a portion of them that have the worst scores. With this reduced feature set, TURF again scores the remaining features and eliminates a portion of the worst-scoring features. This process is repeated until a predefined number of features remain.</p>
<p>Essentially, TURF is equivalent to <a href="http://scikit-learn.org/stable/modules/feature_selection.html#recursive-feature-elimination">Recursive Feature Elimination</a>, as <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html">implemented</a> in scikit-learn. Below is a code sample of how RFE can be used in conjunction with the Relief-based algorithms.</p>
<pre><code class="python">import pandas as pd
import numpy as np
from sklearn.pipeline import make_pipeline
from skrebate import ReliefF
from sklearn.feature_selection import RFE
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

genetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'
                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.csv.gz',
                           sep='\t', compression='gzip')

features, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values

clf = make_pipeline(RFE(ReliefF(), n_features_to_select=2),
                    RandomForestClassifier(n_estimators=100))

print(np.mean(cross_val_score(clf, features, labels)))
&gt;&gt;&gt; 0.795
</code></pre>

<h2 id="acquiring-feature-importance-scores">Acquiring feature importance scores</h2>
<p>In some cases, it may be useful to compute feature importance scores without actually performing feature selection. We have made it possible to access all Relief-based algorithm's scores via the <code>feature_importances_</code> attribute. Below is a code example showing how to access the scores from the ReliefF algorithm.</p>
<pre><code class="python">import pandas as pd
import numpy as np
from sklearn.pipeline import make_pipeline
from skrebate import ReliefF
from sklearn.model_selection import train_test_split

genetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'
                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.csv.gz',
                           sep='\t', compression='gzip')

features, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values

# Make sure to compute the feature importance scores from only your training set
X_train, X_test, y_train, y_test = train_test_split(features, labels)

fs = ReliefF()
fs.fit(X_train, y_train)

for feature_name, feature_score in zip(genetic_data.drop('class', axis=1).columns,
                                       fs.feature_importances_):
    print(feature_name, '\t', feature_score)

&gt;&gt;&gt;N0    -0.0000166666666667
&gt;&gt;&gt;N1    -0.006175
&gt;&gt;&gt;N2    -0.0079
&gt;&gt;&gt;N3    -0.006275
&gt;&gt;&gt;N4    -0.00684166666667
&gt;&gt;&gt;N5    -0.0104416666667
&gt;&gt;&gt;N6    -0.010275
&gt;&gt;&gt;N7    -0.00785
&gt;&gt;&gt;N8    -0.00824166666667
&gt;&gt;&gt;N9    -0.00515
&gt;&gt;&gt;N10   -0.000216666666667
&gt;&gt;&gt;N11   -0.0039
&gt;&gt;&gt;N12   -0.00291666666667
&gt;&gt;&gt;N13   -0.00345833333333
&gt;&gt;&gt;N14   -0.00324166666667
&gt;&gt;&gt;N15   -0.00886666666667
&gt;&gt;&gt;N16   -0.00611666666667
&gt;&gt;&gt;N17   -0.007325
&gt;&gt;&gt;P1    0.108966666667
&gt;&gt;&gt;P2    0.111
</code></pre>

<p>Higher positive scores indicate that the features are likely predictive of the outcome, whereas negative scores indicate that the features are likely noise. We generally recommend removing all features with negative scores at a minimum.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../examples/GAMETES_Example/" class="btn btn-neutral float-right" title="GAMETES Example">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../installing/" class="btn btn-neutral" title="Installation"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
      <p>Copyright &copy; 2016-Present <a href="http://www.randalolson.com">Randal S. Olson</a>, <a href="https://github.com/pschmitt52">Pete Schmitt</a>, and <a href="http://ryanurbanowicz.com">Ryan J. Urbanowicz</a></p>
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/EpistasisLab/scikit-rebate" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../installing/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../examples/GAMETES_Example/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="../js/theme.js"></script>

</body>
</html>
